% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/word_embeddings.R
\name{prepare_w2v_embeddings}
\alias{prepare_w2v_embeddings}
\title{prepare_w2v_embeddings}
\usage{
prepare_w2v_embeddings(texts, embedding_dim, tokenizer)
}
\arguments{
\item{texts}{Character vector of raw text from training data.}

\item{embedding_dim}{Dimensionality of word embeddings. Options are 25, 50, 100, 200.}

\item{tokenizer}{Pre-fit keras text tokenizer.}
}
\description{
This function trains a word2vec model to create custom word embeddings from the training data set.
}
\details{
For a good introduction to word2vec model see Distributed Representations of Words and Phrases and their Compositionality (Mikolov et al., 2013)
}
\note{
Embeddings are saved as Rdata to a folder called embeddings with the file format "tweet_wv2_\{embedding_dim\}.rda"
}
