% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_models.R
\name{evaluate}
\alias{evaluate}
\title{evaluate}
\usage{
evaluate(model_path, X_test, y_test)
}
\arguments{
\item{model_path}{Path to HDF5 file containing model. Should be of the form "models/\{model type\}_\{embedding type\}_\{embedding dimensionality\}d.h5"}

\item{X_test}{data.frame or matrix of vectorized Tweets}

\item{y_test}{Labels for testing data. 0 for liberal, 1 for conservative.}
}
\value{
List of performance metrics. Currently, a confusion matrix, overall prediction accuracy, precision, recall, and F1 score are return.
}
\description{
This function evaluates the performance of a trained model.
}
\examples{
data("ideo_tweets")
ideo_tokenizer <- text_tokenizer(num_words=20000)
ideo_tokenizer <- fit_text_tokenizer(ideo_tokenizer, ideo_tweets$text)
texts <- texts_to_vectors(ideo_tweets$text, ideo_tokenizer)
labels <- tweets$ideo_cat

train_test <- train_test_split(texts, labels)

evaluate("models/bi-lstm_w2v_25d.h5", train_test$X_test, train_test$y_test)
}
